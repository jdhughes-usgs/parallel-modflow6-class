{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the basin example base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib as pl\n",
    "\n",
    "import flopy\n",
    "from flopy.discretization import StructuredGrid\n",
    "from flopy.mf6.utils import Mf6Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import containerized functionality from defaults.py\n",
    "from defaults import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel settings\n",
    "\n",
    "1. Set voronoi to `True` to process Voronoi grid base and parallel models.\n",
    "2. Set the number of models in the row and column directions. NOTE: Set nrow_blocks or ncol_blocks to 0 to load a model split with metis or if a Voronoi grid model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voronoi = False\n",
    "nrow_blocks, ncol_blocks = 8, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ws, parallel_ws = get_workspaces(nrow_blocks, ncol_blocks, voronoi=voronoi)\n",
    "base_ws, parallel_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the base basin model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sim = flopy.mf6.MFSimulation.load(\n",
    "    sim_name=\"basin\", \n",
    "    sim_ws=base_ws,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_gwf = base_sim.get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the parallel basin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sim = flopy.mf6.MFSimulation.load(\n",
    "    sim_name=\"basin\", \n",
    "    sim_ws=parallel_ws,\n",
    "    verbosity_level=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the node mapping array for the parallel basin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = parallel_ws / \"mfsplit_node_mapping.json\"\n",
    "mfsplit = Mf6Splitter(base_sim)\n",
    "mfsplit.load_node_mapping(new_sim, json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the multi-model and single model heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_head = np.squeeze(base_gwf.output.head().get_data())\n",
    "hmin, hmax = (\n",
    "    base_head.min(),\n",
    "    np.where(base_head < 1e30, base_head, 0).max(),\n",
    ")\n",
    "contours = np.arange(0, 100, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a dictionary with the model heads for each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = list(new_sim.model_names)\n",
    "head_dict = {}\n",
    "for modelname in model_names:\n",
    "    mnum = int(modelname.split(\"_\")[-1])\n",
    "    head = new_sim.get_model(modelname).output.head().get_data()\n",
    "    head_dict[mnum] = head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a single head array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_head = mfsplit.reconstruct_array(head_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(figwidth, figheight * 1.3333))\n",
    "t = new_head - base_head\n",
    "hv = [new_head, base_head, t]\n",
    "titles = [\"Multiple models\", \"Single model\", \"Multiple - single\"]\n",
    "for idx in range(3):\n",
    "    ax = fig.add_subplot(3, 1, idx + 1)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_title(titles[idx])\n",
    "\n",
    "    if idx < 2:\n",
    "        levels = contours\n",
    "        vmin = hmin\n",
    "        vmax = hmax\n",
    "    else:\n",
    "        levels = None\n",
    "        vmin = None\n",
    "        vmax = None\n",
    "\n",
    "    pmv = flopy.plot.PlotMapView(model=base_gwf, ax=ax, layer=0)\n",
    "    h = pmv.plot_array(hv[idx], vmin=vmin, vmax=vmax)\n",
    "    if levels is not None:\n",
    "        c = pmv.contour_array(\n",
    "            hv[idx],\n",
    "            levels=levels,\n",
    "            colors=\"white\",\n",
    "            linewidths=0.75,\n",
    "            linestyles=\":\",\n",
    "        )\n",
    "        plt.clabel(c, fontsize=8)\n",
    "    if not voronoi:\n",
    "        pmv.plot_inactive()\n",
    "    plt.colorbar(h, ax=ax, shrink=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
